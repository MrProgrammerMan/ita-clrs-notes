---
title: 1.1 Excercises
id: 20250919112654
tags: []
---

# 1.1 Excercises
1. When fetching data for use in statistics from a database, the database may not have indexed the data to optimize for those requests. You may download very large amounts of data, then have to sift through it locally. This will often require sorting in several way, say to find the median purchase amount of your costumers.
   In robotics in maufacturing, finding the shortest distance for an arm, car, or other machanical and autonomous system to move is important for production efficiency.
2. Speed, development time, electricity consumption, code readability, adaptability are some measures of efficiency of an algorithm.
3. The linked list is flexible in that it can quickly be modified without having to move large portions of the list. However, looping through the list is slower than for, say, a simple array. It also requires more memory and needs to be allocated on the heap.
4. They both look at finding the shortest path given by start and end points. The travelling salesperson problem, however, involves many such problems strung together, making the number of possible answers extremely large. Thus, it's not enough to determine the shortest path between the points. One must also determine which points to find the shortest path between(the order of stops).
5. In a system which performs a simple action very often(many times per second), the efficiency of the entire system is basically equivalent to the efficiency of the algorithm its running. For example, there are many network nodes, routers, that route request through the internet. For this purpose, the impact of using a suboptimal algorithm(even if it's just slightly slower) is so large due to the scale, that only the best algorithm will do. It would be insane not to invest the time and resources into implementing the fastest possible solution. Often the decision falls on the impact the algorithm has on the overall system. For example, if a system needs to sort 10 numbers every hour, it doesnt really matter if it uses the quickest algorithm, as improving it won't make the system noticibly faster. If, however, a distributed high-load web service relies heavily on sorting very large amounts of number many times per second, it will be extremely expensive in terms of server space to spin up more instances of the service if the sorting algorithm used is slow.
6. If an algorithm has to compress a live video feed for streaming, it will probably be more efficient if it can consider the input gradually as it comes in, instead of having to treat chinks of the video as completely individual, compression them in isolation. If instead an algorithm considers a persons recipe rataings to find recommended recipes, it will likely be able to look at the entire history and process it. This kind of application is not speed-critical in the way where the transfer or amount of data significantly affects the algorithms use case.